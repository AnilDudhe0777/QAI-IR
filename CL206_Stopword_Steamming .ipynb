{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "taVgbGqbYsUk"
   },
   "source": [
    "## Q-6 Stopword Steamming\n",
    "Write a program for pre-processing of a text document such as stop word removal, stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "87_bTOWeYn4k",
    "outputId": "490b93f0-1d5a-4b47-f22d-36dfc05045fd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'sample', 'sentence', ',', 'showing', 'off', 'the', 'stop', 'words', 'filtration', '.']\n"
     ]
    }
   ],
   "source": [
    "sent = \"This is a sample sentence, showing off the stop words filtration.\"\n",
    "stop_words = set(stopwords.words('english'))\n",
    "word_tokens = word_tokenize(sent)\n",
    "print(word_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample', 'sentence', ',', 'showing', 'stop', 'words', 'filtration', '.']\n"
     ]
    }
   ],
   "source": [
    "filtered_sent = [word for word in word_tokens if word.lower() not in stop_words]\n",
    "print(filtered_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EXiBKnF7bjw1",
    "outputId": "fbdeafe1-4943-450d-ac5e-b29c94e88130"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Removing Stopwords: ['Integrating', 'non-traditional', 'assessment', 'methods', 'like', 'project-based', 'learning', 'and', 'competency-based', 'evaluation', 'could', 'provide', 'a', 'more', 'comprehensive', 'picture', 'of', 'student', 'performance.', 'In', 'conclusion,', 'student', 'performance', 'and', 'monitoring', 'systems', 'offer', 'immense', 'potential', 'for', 'enhancing', 'educational', 'outcomes', 'by', 'leveraging', 'data,', 'technology,', 'and', 'collaboration.']\n",
      "Length: 39\n"
     ]
    }
   ],
   "source": [
    "file = open(\"input.txt\")\n",
    "line = file.read()\n",
    "words = line.split()\n",
    "print(\"Before Removing Stopwords:\",words)\n",
    "print(\"Length:\",len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "vV7u5uSkbmMe"
   },
   "outputs": [],
   "source": [
    "for word in words:\n",
    "    if word not in stop_words:\n",
    "        file = open('output.txt','a')\n",
    "        file.write(\" \"+word)\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SiLtwqXZcDQr",
    "outputId": "63bb00bc-d614-4f2d-e9fd-e70a943fa5d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Removing Stopwords: ['Integrating', 'non-traditional', 'assessment', 'methods', 'like', 'project-based', 'learning', 'competency-based', 'evaluation', 'could', 'provide', 'comprehensive', 'picture', 'student', 'performance.', 'In', 'conclusion,', 'student', 'performance', 'monitoring', 'systems', 'offer', 'immense', 'potential', 'enhancing', 'educational', 'outcomes', 'leveraging', 'data,', 'technology,', 'collaboration.', 'Integrating', 'non-traditional', 'assessment', 'methods', 'like', 'project-based', 'learning', 'competency-based', 'evaluation', 'could', 'provide', 'comprehensive', 'picture', 'student', 'performance.', 'In', 'conclusion,', 'student', 'performance', 'monitoring', 'systems', 'offer', 'immense', 'potential', 'enhancing', 'educational', 'outcomes', 'leveraging', 'data,', 'technology,', 'collaboration.']\n",
      "Length: 62\n"
     ]
    }
   ],
   "source": [
    "file = open(\"output.txt\")\n",
    "line = file.read()\n",
    "words = line.split()\n",
    "print(\"Before Removing Stopwords:\",words)\n",
    "print(\"Length:\",len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p2XDsM5ZdJcy",
    "outputId": "ab47b8ed-f0f0-4e1f-c150-1361fa332f1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program : program\n",
      "programmer : programm\n",
      "programming : program\n",
      "programs : program\n",
      "programmers : programm\n"
     ]
    }
   ],
   "source": [
    "ps=PorterStemmer()\n",
    "sample = ['program', 'programmer', 'programming', 'programs', 'programmers']\n",
    "for s in sample:\n",
    "    print(s,\":\", ps.stem(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0SbPw9_ydK1P",
    "outputId": "6628738c-541d-4131-e5a3-b604d1ae2d15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Programmers', 'program', 'with', 'different', 'programming', 'languages']\n",
      "Programmers : programm\n",
      "program : program\n",
      "with : with\n",
      "different : differ\n",
      "programming : program\n",
      "languages : languag\n"
     ]
    }
   ],
   "source": [
    "sent = \"Programmers program with different programming languages\"\n",
    "words = word_tokenize(sent)\n",
    "print(words)\n",
    "for word in words:\n",
    "    print(word,\":\", ps.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
